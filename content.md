---
meta:
  caption: "Aljosa's Web Corner"
  title: "Aljosa Osep, Ph.D."
  css_link: "https://latex.now.sh/style.min.css"
  profile_picture: "<img src=\"img/aljosa.jpg\" alt=\"In Colombia, my fave\" width=\"200\" align=\"left\" style=\"padding:10px;\">"
  links: >
    <br><b>
    <a href="rss_2020_camready.html">Research Statement (2019)</a>
    <a href="https://twitter.com/AljosaOsep">Twitter</a>
    <a href="https://scholar.google.de/scholar?hl=en&as_sdt=0%2C5&q=aljosa+osep&oq=a">Scholar</a>
    </b>


research_topics:
  description: |
    My research focuses on enabling AI systems to robustly understand the dynamic, 3D world from raw sensor streams, such as video and LiDAR. Key areas include learning directly from raw data, tracking and segmenting objects, understanding complex spatiotemporal scenes, and predicting future events in open-world environments. Hover over each topic below to explore related publications.

  topics:
    - title: "Learning From Raw Sensory Data"
      image: "raw.gif"
      papers:
        - title: "Large-Scale Object Mining for Object Discovery from Unlabeled Video (ICRA 2019)"
          link: "https://arxiv.org/pdf/1903.00362"
        - title: "4D Generic Video Object Proposals (ICRA 2020)"
          link: "https://arxiv.org/pdf/1901.09260"
        - title: "Learning to Discover and Detect Objects (NeurIPS 2022)"
          link: "https://arxiv.org/abs/2210.10774"
        - title: "Pix2Map: Cross-modal Retrieval for Inferring Street Maps from Images (CVPR 2023)"
          link: "https://arxiv.org/abs/2301.04224"
        - title: "What Moves Together Belongs Together (CVPR 2024)"
          link: "https://arxiv.org/abs/2402.19463"
        - title: "Better Call SAL: Towards Learning to Segment Anything in Lidar (ECCV 2024)" 
          link: "https://arxiv.org/abs/2403.13129"
        - title: "Towards Learning to Complete Anything in Lidar (ICML 2025)"
          link: "https://arxiv.org/abs/2504.12264"
  
    - title: "4D Scene Understanding"
      image: "cal_vid.gif"
      papers:
        - title: "Scene Flow Propagation for Semantic Mapping and Object Discovery in Dynamic Street Scenes (IROS 2016)"
          link: "https://www.vision.rwth-aachen.de/media/papers/paper_compressed.pdf"
        - title: "4D Generic Video Object Proposals (ICRA 2020)"
          link: "https://arxiv.org/pdf/1901.09260"
        - title: "4D Panoptic LiDAR Segmentation (CVPR 2021)"
          link: "https://arxiv.org/abs/2102.12472"
        - title: "Zero-Shot 4D Lidar Panoptic Segmentation (CVPR 2025)"
          link: "https://arxiv.org/abs/2504.00848"


    - title: "Tracking and Panoptic Perception"
      image: "tubes_4d.gif"
      papers:
        - title: "Combined Image- and World-Space Tracking in Traffic Scenes (ICRA 2017)"
          link: "https://arxiv.org/abs/1809.07357"
        - title: "Track, then Decide: Category-Agnostic Vision-based Multi-Object Tracking (ICRA 2018)"
          link: "https://arxiv.org/abs/1712.07920"
        - title: "MOTS: Multi-Object Tracking and Segmentation (CVPR 2019)"
          link: "https://arxiv.org/abs/1902.03604"
        - title: "HOTA: A Higher Order Metric for Evaluating Multi-Object Tracking (IJCV 2020)"
          link: "https://arxiv.org/pdf/2009.07736.pdf"
        - title: "STEP: Segmenting and Tracking Every Pixel (NeurIPS Datasets 2022)"
          link: "https://arxiv.org/abs/2102.11859"
        - title: "Opening up Open-World Tracking (CVPR 2022)"
          link: "https://arxiv.org/abs/2104.11221"
        - title: "PolarMOT: How far can geometric relations take us in 3D multi-object tracking? (ECCV 2022)"
          link: "https://arxiv.org/abs/2208.01957"
        - title: "EagerMOT: 3D Multi-Object Tracking via Sensor Fusion (ICRA 2021)"
          link: "https://arxiv.org/abs/2104.14682"


    - title: "Forecasting & Behavioral AI"
      image: "dendorfer_accv_2020.jpg"
      papers:
        - title: "Unsupervised Learning of Shape-Motion Patterns for Objects in Urban Street Scenes (BMVC 2016)"
          link: "https://www.vision.rwth-aachen.de/media/papers/bmvc16_klostermann_final.pdf"
        - title: "Quo Vadis: Is Trajectory Forecasting the Key Towards Long-Term Multi-Object Tracking? (NeurIPS 2022)"
          link: "https://arxiv.org/abs/2210.07681"
        - title: "Forecasting from LiDAR via Future Object Detection (CVPR 2022)"
          link: "https://arxiv.org/abs/2203.16297"


news:
  - date: "June 2024"
    title: "I joined NVIDIA as a Senior Research Scientist!"
  - date: "March 2024"
    title: >
      Our [paper](https://arxiv.org/abs/2403.13129) on *Learning to segment anything in Lidar (SAL)*
      was featured at GTC2024! Check out the [NVIDIA AI Tools for Autonomous Vehicle Developers](https://youtu.be/LLSuUBObttE?si=WvQFphni5vX7Es5I).
  - date: "September 2022"
    title: >
      Two papers accepted to NeurIPS 2022! Excited to be back to NOLA soon!
  - date: "June 2022"
    title: >
      I was featured in the **TWIMLAI podcast!** Listen to the
      [episode](https://twimlai.com/podcast/twimlai/on-the-path-towards-robot-vision-with-aljosa-osep/).
  - date: "August 2021"
    title: >
      I am one of the three persons listed as outstanding reviewers for all top-tier computer vision
      conferences in 2020/21. See [the informal analysis](https://twitter.com/simon_niklaus/status/1433127773409665025?s=20)
      by Simon Niklaus! Thanks to ACs for the recognition and Simon for pointing this out.
  - date: "August 2021"
    title: >
      I was awarded Borchers Plaquette at RWTH Aachen University for outstanding doctoral dissertation!
  - date: "June 2021"
    title: >
      I am spending a year at the Carnegie Mellon University (The Robotics Institute,
      [CMU Argo AI Center for Autonomous Vehicle Research](https://labs.ri.cmu.edu/argo-ai-center/)) in Pittsburgh!
      Thanks to [Deva Ramanan](https://www.cs.cmu.edu/~deva/) for hosting me!
  - date: "April 2020"
    title: >
      Learned how to make pancakes! Check out the
      [evidence](https://photos.app.goo.gl/uMeWKNmqPUcuwyXQ6).

students:
  - name: "Ayça Takmaz"
    affiliation: "(NVIDIA, intern)"
    next_step: "<i>ETH Zurich</i>"
  - name: "Yushan Zhang"
    affiliation: "(NVIDIA, intern)"
    next_step: "<i>Linköping University</i>"
  - name: "Neehar Peri"
    affiliation: "(NVIDIA, intern)"
    next_step: "<i>Carnegie Mellon University</i>"
  - name: "Xindi Wu"
    affiliation: "(CMU, 2022)"
    next_step: "→ <i>Princeton</i>"
  - name: "Vladimir Fomenko"
    affiliation: "(TUM, 2022)"
    next_step: "→ <i>Microsoft, OpenAI</i>"
  - name: "Anirudh S Chakravarthy"
    affiliation: "(CMU, 2022)"
    next_step: "→ <i>Cruise AI</i>"
  - name: "Meghana Reddy Ganesina"
    affiliation: "(CMU, 2022)"
    next_step: "→ <i>Zoox</i>"
  - name: "Abhinav Agarwalla"
    affiliation: "(CMU, 2022)"
    next_step: "→ <i>Prior Argo AI, now Neural Magic</i>"
  - name: "Vladimir Yugay"
    affiliation: "(TUM, 2022)"
    next_step: "→ <i>University of Amsterdam</i>"
  - name: "Alexandr Kim"
    affiliation: "(TUM, 2019-2021)"
    next_step: "→ <i>Meta</i>"
  - name: "Yang Liu"
    affiliation: "(TUM, 2020)"
    next_step: "→ <i>Huawei</i>"
  - name: "Manuel Kolmet"
    affiliation: "(TUM, 2021)"
    next_step: "→ <i>GLASS Imaging</i>"
  - name: "Anselm Coogan"
    affiliation: "(TUM, 2021)"
    next_step: "→ <i>Scandit</i>"
  - name: "Maximilian Kempa"
    affiliation: "(TUM, 2020)"
    next_step: "→ <i>Bosch</i>"
  - name: "Mehmet Aygün"
    affiliation: "(TUM, 2020)"
    next_step: "→ <i>University of Edinburgh</i>"
  - name: "Johannes Gross"
    affiliation: "(RWTH Aachen, 2019)"
  - name: "Deyvid Kochanov"
    affiliation: "(RWTH Aachen, 2016)"
  - name: "Dirk Klostermann"
    affiliation: "(RWTH Aachen, 2015)"
    next_step: "→  <i>BMW</i>"

talks:
  - date: "June 2024"
    title: >
      CVPR 2024 Area Chair Panel, invited talk: Learning To Understand The World From Video,
      [Slides](https://docs.google.com/presentation/d/1JCy1TARAlcT0HIT07uRUic1iPsMejIDqYckeRTOvzn8/edit?usp=sharing)
  - date: "June 2023"
    title: >
      CVPR 2023, Visual Perception via Learning in an Open World, invited talk:
      Learning To Understand The World From Video,
      [Slides](https://docs.google.com/presentation/d/1DgNPaJm6WWjgNdIjdDiyaLw5d-2Tu5hvraqWJSmGK3g/edit?usp=sharing)
  - date: "June 2023"
    title: >
      [University of Ljubljana, invited talk: Learning To Understand The World From Video](https://fri.uni-lj.si/sl/dogodek/gostujoce-predavanje-learning-understand-world-video),
      [Slides](https://docs.google.com/presentation/d/1w__6jKhNgzwT66oMcUyKgvGJEwgOVMlH-12WAuAHaKc/edit?usp=sharing)
  - date: "February 2023"
    title: >
      [University of Ljubljana, invited talk: Learning To Understand The World From Video](https://fri.uni-lj.si/sl/dogodek/gostujoce-predavanje-learning-understand-world-video),
      [Slides](https://docs.google.com/presentation/d/1w__6jKhNgzwT66oMcUyKgvGJEwgOVMlH-12WAuAHaKc/edit?usp=sharing)
  - date: "October 2022"
    title: >
      ECCV’22 Workshop on 3D Perception in Autonomous Driving
      [Details](https://innoviz.tech/eccv-speakers),
      [Slides](tbd)
  - date: "October 2022"
    title: >
      ECCV’22 Workshop on Cross-Modal Human-Robot Interaction
      [Details](https://cross-modal-human-robot-interaction.github.io/speakers.html),
      [Slides](tbd)
  - date: "June 2022"
    title: >
      Slovenian data-science meetup talk (in Slovenian):
      [Slides](https://docs.google.com/presentation/d/1snIpyxQaFQYvSvx_V56I1VVqow-3UlSlDw9gIEH8IsI/edit?usp=sharing)
  - date: "April 2022"
    title: >
      UT Austin AI colloquium, **Unifying Segmentation, Tracking, and Forecasting**,
      [Slides](https://docs.google.com/presentation/d/1us6m0LwJ3_Ai04yS13ztskCwQ4GCU-Vb5uLP41qs9Vc/edit?usp=sharing)
  - date: "September 2021"
    title: >
      ICCV’21 Workshop on 3D Object Detection from Images, **4D Panoptic LiDAR Segmentation**,
      [Slides](https://docs.google.com/presentation/d/1NdMZ1ZHlGMkUBjvLEjcNyR6sWovXPO2OJEF8QrDNqmM/edit?usp=sharing)
  - date: "July 2021"
    title: >
      RSS 2021 on Workshop on Behavioral Inference of Remotely Sensed Multi-agent Systems,
      invited talk, **Tracking Every Object and Pixel**,
      [Slides](https://docs.google.com/presentation/d/1MvjuIpNDPFLveJDWb6IU2QjeKHHhkZv0jk2aFgOdAI0/edit?usp=sharing)
  - date: "July 2021"
    title: >
      RSS 2021 Workshop on Perception and Control for Autonomous Navigation in Crowded, Dynamic Environments,
      invited talk, **Tracking Every Object and Pixel**,
      [Slides](https://docs.google.com/presentation/d/1osEVQOwyByzjnrFJ8GD13GY6A2BTufcdZAgX9RPs74k/edit?usp=sharing),
      [Talk](https://youtu.be/Crur1kKLFmA)
  - date: "June 2021"
    title: >
      [CVPR'21 JackRobbot dataset and benchmark (JRDB) workshop talk](https://jrdb.erc.monash.edu/workshops/cvpr2021),
      **Tracking Every Object and Pixel**,
      [Slides](https://docs.google.com/presentation/d/1AdtfJFmpbB1Hi6EpcQMzB5ylfk03p2-_DI7ZEgxmz8o/edit?usp=sharing)
  - date: "April 2021"
    title: >
      Cornell Robotics Seminar,
      [Slides](https://docs.google.com/presentation/d/1r19VsfVVRboE-kb4dVCUqz8xNeWKtmxqHDNj27kR4Us/edit?usp=sharing)
  - date: "September 2020"
    title: >
      University of Bonn - Research talk,
      [Slides](https://docs.google.com/presentation/d/1GCDF-FBnXW9i0NrSTqB20BRgpN3uOMxWgGwp3XVzc5A/edit?usp=sharing)
  - date: "June 2019"
    title: >
      RWTH Aachen University - Thesis Defense,
      [Slides](https://docs.google.com/presentation/d/e/2PACX-1vQ4POvCXfiL1fW5zoxpfEoOJDFNUxgbvoGKLWXuyj2rEz6I4xSeYCp9mhIFrxLfM9ckpg8zOlcDlBZ4/pub?start=false&loop=false&delayms=3000)
  - date: "June 2019"
    title: >
      Georgia Tech - Research Talk,
      [Slides](https://docs.google.com/presentation/d/e/2PACX-1vSelDf9pZ8yAeMYGbndWO_OyqR2faPCum5G1vWKvGicB7s7E0LG3oAMD7iSTWiG_-RDT6TwAbg6fb5I/pub?start=false&loop=false&delayms=3000)
  - date: "March 2019"
    title: >
      Carnegie Mellon University VASC Seminar,
      [Slides](https://docs.google.com/presentation/d/e/2PACX-1vTKleY9LI8z4Tc2FIXVd0woFKqMlkXjGwPpNOZTtw1VDUCucoxce4FFCe0Mi6g_wIrtCRv6kv3tw3Wk/pub?start=false&loop=false&delayms=3000)


teaching:
  - date: "Summer 2022"
    title: >
      Lecturer for [IN2375: Computer Vision III: Detection, Segmentation and Tracking (CV3DST)](https://dvl.in.tum.de/teaching/cv3dst-ss22/) (TU Munich)
  - date: "Summer 2022"
    title: >
      Lecturer for [IN2346: Introduction to Deep Learning (I2DL)](https://dvl.in.tum.de/teaching/i2dl-ss22/) (TU Munich)
  - date: "Winter 2020/21"
    title: >
      [IN2157: Fundamental Algorithms](https://dvl.in.tum.de/teaching/fundalg-ws20/) (TU Munich, lecturer)
  - date: "Summer 2019/20"
    title: >
      IN2375: Computer Vision 3: Detection, Segmentation and Tracking (TU Munich, guest lecturer),
      [Lectures available on YouTube](https://t.co/tTTtpKN2pi?amp=1)
  - date: "Winter 2019/20"
    title: >
      IN2157: Fundamental Algorithms (TU Munich, lecturer),
      [TUM Moodle](https://www.moodle.tum.de/course/view.php?id=52150),
      IN2375: Computer Vision 3: Detection, Segmentation and Tracking (TU Munich, guest lecturer)
  - date: "Summer 2016/17"
    title: >
      Machine Learning (RWTH Aachen, exercise class)
  - date: "Winter 2014/15"
    title: >
      Computer Vision (RWTH Aachen, exercise class)
  - date: "Winter 2013/14"
    title: >
      Machine Learning (RWTH Aachen, exercise class)

service:
  - title: >
      Area Chair (AC) for ICLR, CVPR, ECCV, ICCV, WACV, ACCV.
  - title: >
      I am the main organizer of
      [6th BMTT MOTChallenge Workshop: Segmenting and Tracking Every Point and Pixel](https://motchallenge.net/workshops/bmtt2021)
      at ICCV'21 workshop, and co-organizer of:
      [7th Workshop on Benchmarking Multi-Target Tracking: How Far Can Synthetic Data Take us?](https://motchallenge.net/workshops/bmtt2022)
      at CVPR'22,
      [Tracking and its many guises Workshop](http://taodataset.org/workshop/) at ECCV'2020,
      [Multi-Object Tracking and Segmentation Workshop](https://motchallenge.net/workshops/bmtt2020) at CVPR'2020.
  - title: >
      Reviewer for (*machine learning, vision conferences*) CVPR, ECCV, ICCV, BMVC, NeurIPS, ICML, ICLR;
      (*robotics conferences*) ICRA, IROS, RSS; (*journals*) IJCV, RAL, TPAMI.
  - title: >
      I am in RSS Pioneers 2021 program committee and on the ECCV'24 organization team!
---


Hi, I'm Aljosa! I am a Senior Research Scientist at NVIDIA, working on learning to understand the dynamic world from raw, unlabeled streams of sensory data.

I come from the Alpine side of Slovenia. I earned my Ph.D. from RWTH Aachen University under the supervision of [Prof. Bastian Leibe](https://www.vision.rwth-aachen.de/person/1/). I was a postdoctoral fellow at the Technical University of Munich and the Robotics Institute, Carnegie Mellon University.